{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50599b14",
   "metadata": {},
   "source": [
    "# Test Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6d8c75-048b-465c-809d-b0343b8e37a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import dump,load\n",
    "from utils import StepwiseDecay as SWD\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "\n",
    "# from sklearn.gaussian_process import GaussianProcessRegressor as GPR\n",
    "# from sklearn.gaussian_process.kernels import ConstantKernel, DotProduct, ExpSineSquared, Matern, RBF\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "from torch import nn\n",
    "import torch\n",
    "from nnr_custom import Torch_Model_BasicRegressor as NNR\n",
    "\n",
    "from modAL.models import BayesianOptimizer, ActiveLearner\n",
    "from modAL.acquisition import max_EI, max_PI, max_UCB, optimizer_EI,optimizer_PI, optimizer_UCB\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99eb81b0-f36c-44af-9915-5e399d1d4e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "fingerprint = 'morgan'\n",
    "model = 'NNR'\n",
    "file_name = \"complete_file_morgan.feather\"\n",
    "config_file_name = 'NNR.json'\n",
    "use_unified_file = True\n",
    "decay_list = [1.0,0.75,0.5,0.25,0.125,0.1,0.05]\n",
    "use_decomposition = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddef2ef",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406f063f-1870-42b3-9386-4a9306d0d6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "file_path = '/data_temp/default_{}/'.format(fingerprint)\n",
    "\n",
    "try:\n",
    "    if use_unified_file == True:\n",
    "        try:\n",
    "            df = pd.read_feather(\"../data\" + file_path + file_name)\n",
    "        except:\n",
    "            df = pd.read_parquet(\"../data\" + file_path + file_name)\n",
    "        df_nan = pd.read_parquet(\"../data\" + file_path + \"assay_id/assay_id_null_file.parquet\")\n",
    "        df_assays = pd.read_parquet(\"../data\" + file_path + \"assay_id/assay_id_file.parquet\")\n",
    "\n",
    "    elif use_unified_file == False:\n",
    "        df_fingerprint = pd.read_parquet(\"../\" + file_path + \"/fingerprint/{}_fingerprint_file.parquet\".format(fingerprint))\n",
    "        df = pd.read_parquet(\"../\" + file_path + \"/preprocessed/preprocessed_file.parquet\")\n",
    "        df_nan = pd.read_parquet(\"../\" + file_path + \"/assay_id/assay_id_null_file.parquet\")\n",
    "        df_assays = pd.read_parquet(\"../\" + file_path + \"/assay_id/assay_id_file.parquet\")\n",
    "    else:\n",
    "        print(\"Incorrect value for 'use_unified_file' parameter passed. Please recheck.\")\n",
    "        pass\n",
    "except:\n",
    "    print(\"Data File not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef88d7f-4cce-492c-aa89-d8e39aa92473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assay_id</th>\n",
       "      <th>squared_pearson_trn</th>\n",
       "      <th>squared_pearson_tst</th>\n",
       "      <th>assay_length_trn</th>\n",
       "      <th>assay_length_tst</th>\n",
       "      <th>assay_length_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>303216</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45</td>\n",
       "      <td>15</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>303260</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45</td>\n",
       "      <td>15</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>737235</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45</td>\n",
       "      <td>15</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   assay_id  squared_pearson_trn  squared_pearson_tst  assay_length_trn  \\\n",
       "1    303216                  NaN                  NaN                45   \n",
       "2    303260                  NaN                  NaN                45   \n",
       "4    737235                  NaN                  NaN                45   \n",
       "\n",
       "   assay_length_tst  assay_length_total  \n",
       "1                15                  60  \n",
       "2                15                  60  \n",
       "4                15                  60  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nan.loc[df_nan['squared_pearson_trn'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152e698e-a306-468c-bdf2-49906f197c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x-----x-----x-----x\n",
      "x-----x-----x-----x\n",
      "x-----x-----x-----x\n"
     ]
    }
   ],
   "source": [
    "# df = df.drop(nan_assays)\n",
    "for i in df_nan.loc[df_nan['squared_pearson_trn'].isnull()]['assay_id']:\n",
    "    df = df.drop(labels = df.loc[df['assay_id']==i].index)\n",
    "df.loc[df['assay_id']==303216].head()\n",
    "print('x-----x-----x-----x')\n",
    "df.loc[df['assay_id']==303260].head()\n",
    "print('x-----x-----x-----x')\n",
    "df.loc[df['assay_id']==737235].head()\n",
    "print('x-----x-----x-----x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4884ce64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON config file for GPR successfully loaded\n"
     ]
    }
   ],
   "source": [
    "# Loading JSON config file\n",
    "try:\n",
    "    with open('../config/' + config_file_name) as f:\n",
    "        params_config = json.load(f)\n",
    "        print('JSON config file for {} successfully loaded'.format(model))\n",
    "except FileNotFoundError:\n",
    "    print('Config file for model {} is missing.Resorting to default params'.format(model))\n",
    "    with open('../config/{}_default.json'.format(model)) as f:\n",
    "        params_config = json.load(f)\n",
    "\n",
    "if os.path.isdir('../models/{0}_{1}/'.format(model,fingerprint)) == False:\n",
    "    os.mkdir('../models/{0}_{1}/'.format(model,fingerprint))\n",
    "\n",
    "if os.path.isdir('../data/data_results/{0}_{1}/'.format(model,fingerprint)) == False:\n",
    "    os.mkdir('../data/data_results/{0}_{1}/'.format(model,fingerprint))\n",
    "\n",
    "if os.path.isdir('../data/data_results/{0}_{1}/plots'.format(model,fingerprint)) == False:\n",
    "    os.mkdir('../data/data_results/{0}_{1}/plots'.format(model,fingerprint))\n",
    "\n",
    "# Creating List of Classifiers\n",
    "clfs = []\n",
    "acquisition_list = []\n",
    "clf_list = []\n",
    "count = 0\n",
    "clf_list_names = []\n",
    "\n",
    "for neural_net in params_config[\"kernel\"]:\n",
    "    if neural_net == \"BasicNNR()\":\n",
    "        clf_type = NNR()\n",
    "    else:\n",
    "        clf_type = NNR()\n",
    "    clf = {\n",
    "        \"type\" : clf_type,\n",
    "        \"name\" : neural_net\n",
    "    }\n",
    "    clfs.append(clf)\n",
    "\n",
    "for function in params_config[\"acquisition\"]:\n",
    "    if function==\"max_EI\":\n",
    "        acquisition_type = max_EI\n",
    "    elif function==\"max_PI\":\n",
    "        acquisition_type = max_PI\n",
    "    elif function==\"max_UCB\":\n",
    "        acquisition_type = max_UCB\n",
    "    else:\n",
    "        acquisition_type = max_EI\n",
    "    acquisition = {\n",
    "        \"type\" : acquisition_type,\n",
    "        \"name\": function\n",
    "    }\n",
    "    acquisition_list.append(acquisition)\n",
    "\n",
    "if params_config[\"optimizer\"] == \"Adam\":\n",
    "    default_optimizer = torch.optim.Adam(lr = params_config)\n",
    "for model_selected in clfs:\n",
    "    for ac_func in acquisition_list:\n",
    "        clf = {\n",
    "            \"model\" :model_selected[\"type\"],\n",
    "            \"model_name\" : model_selected[\"name\"],\n",
    "            \"acquisition_function\" :ac_func[\"type\"],\n",
    "            \"acquisition_function_name\" : ac_func[\"name\"]\n",
    "        }\n",
    "        clf_list.append(clf)\n",
    "        clf_list_names.append(\"model_{}_{}\".format(clf[\"model_name\"], clf[\"acquisition_function_name\"]))\n",
    "        count+=1\n",
    "\n",
    "clf_list_names = ['assay_id','subset_size_trn','total_length'] + clf_list_names\n",
    "\n",
    "num_iterations=params_config[\"iterations\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ce108e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_trn = [[0 for i in range(len(clf_list)+3)] for j in range(len(df[\"assay_id\"].unique()+1))]\n",
    "pearson_tst = [[0 for i in range(len(clf_list)+3)] for j in range(len(df[\"assay_id\"].unique()+1))]\n",
    "\n",
    "pearson_values_graph = [[0 for i in range(len(acquisition_list))] for j in range(num_iterations)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730b3a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80d6e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached selected assay at time = 251.78277468681335\n",
      "\n",
      "The current assay id is 688239 and initialisation size is 3299\n",
      "\n",
      "Subset selected in 0.9444200992584229\n",
      "Selecte initial training subset 0.9454185962677002\n",
      "Data is for model Matern() with acc_func max_UCB\n",
      "Before model creation : 0.946418046951294\n",
      "After model creation and training 1.0214197635650635\n",
      "Time taken to query 3.726145029067993\n",
      "Time taken to query 6.578185319900513\n",
      "Time taken to query 9.352575302124023\n",
      "Time taken to query 12.163638591766357\n",
      "Time taken to query 15.3292555809021\n",
      "Time taken to query 18.474580764770508\n",
      "Time taken to query 21.58100438117981\n",
      "Time taken to query 24.700552225112915\n",
      "Time taken to query 27.998998641967773\n",
      "Time taken to query 31.433273792266846\n",
      "Time taken to query 34.93605351448059\n",
      "Time taken to query 38.69040560722351\n",
      "Time taken to query 42.30279755592346\n",
      "Time taken to query 46.196889877319336\n",
      "Time taken to query 50.230305194854736\n",
      "Time taken to query 54.25097441673279\n",
      "Time taken to query 58.37383770942688\n",
      "Time taken to query 62.56582689285278\n",
      "Time taken to query 66.97509717941284\n",
      "Time taken to query 71.45971894264221\n",
      "Time taken to query 76.09237599372864\n",
      "Time taken to query 80.52881264686584\n",
      "Time taken to query 85.29553627967834\n",
      "Time taken to query 90.18995451927185\n",
      "Time taken to query 95.0388560295105\n",
      "Training Process for acc func max_UCB has been completed in \n",
      "Data is for model Matern() with acc_func max_PI\n",
      "Before model creation : 101.38596248626709\n",
      "After model creation and training 101.4474105834961\n",
      "Time taken to query 104.1143639087677\n",
      "Time taken to query 106.94736289978027\n",
      "Time taken to query 109.7139163017273\n",
      "Time taken to query 112.84400987625122\n",
      "Time taken to query 115.89049577713013\n",
      "Time taken to query 118.8048243522644\n",
      "Time taken to query 122.03220796585083\n",
      "Time taken to query 125.2401123046875\n",
      "Time taken to query 128.43299555778503\n",
      "Time taken to query 131.96464896202087\n",
      "Time taken to query 135.40963411331177\n",
      "Time taken to query 138.89975357055664\n",
      "Time taken to query 142.58582043647766\n",
      "Time taken to query 146.39191722869873\n",
      "Time taken to query 150.43594098091125\n",
      "Time taken to query 154.38793444633484\n",
      "Time taken to query 158.46704697608948\n",
      "Time taken to query 162.5253026485443\n",
      "Time taken to query 166.71193647384644\n",
      "Time taken to query 171.19755101203918\n",
      "Time taken to query 175.80834484100342\n",
      "Time taken to query 180.2688455581665\n",
      "Time taken to query 184.92998433113098\n",
      "Time taken to query 189.54239296913147\n",
      "Time taken to query 194.3542594909668\n",
      "Training Process for acc func max_PI has been completed in \n",
      "Data is for model Matern() with acc_func max_EI\n",
      "Before model creation : 200.5535535812378\n",
      "After model creation and training 200.62152981758118\n",
      "Time taken to query 203.22905206680298\n",
      "Time taken to query 205.95292854309082\n",
      "Time taken to query 208.79789900779724\n",
      "Time taken to query 211.7098422050476\n",
      "Time taken to query 214.67810773849487\n",
      "Time taken to query 217.6612012386322\n",
      "Time taken to query 220.75476813316345\n",
      "Time taken to query 224.04544806480408\n",
      "Time taken to query 227.32034873962402\n",
      "Time taken to query 230.60471367835999\n",
      "Time taken to query 234.11187934875488\n",
      "Time taken to query 237.73537683486938\n",
      "Time taken to query 241.46727800369263\n",
      "Time taken to query 245.15333199501038\n",
      "Time taken to query 248.7658302783966\n",
      "Time taken to query 252.59737086296082\n",
      "Time taken to query 256.5494558811188\n",
      "Time taken to query 260.80188751220703\n",
      "Time taken to query 264.95170760154724\n",
      "Time taken to query 269.2661678791046\n",
      "Time taken to query 273.60702323913574\n",
      "Time taken to query 278.14554381370544\n",
      "Time taken to query 282.7434844970703\n",
      "Time taken to query 287.48331451416016\n",
      "Time taken to query 292.1562342643738\n",
      "Training Process for acc func max_EI has been completed in \n",
      "Reached selected assay at time = 784.8952312469482\n"
     ]
    }
   ],
   "source": [
    "list_subset_sizes = []\n",
    "list_total_sizes = []\n",
    "row = 0\n",
    "column = 0\n",
    "pvg_column = 0\n",
    "pvg_row = 0\n",
    "\n",
    "flag_first_assay = 688239\n",
    "# flag_first_assay = 517\n",
    "# flag_first_assay = 70695\n",
    "\n",
    "first_start = time.time()\n",
    "# try:\n",
    "decay_tracker = SWD(decay_list)\n",
    "count = 0\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "for assay_id in df['assay_id'].unique():\n",
    "    if assay_id == np.int64(flag_first_assay):\n",
    "        print('Reached selected assay at time = {}'.format(time.time() - first_start))\n",
    "    \n",
    "    df_current = df.loc[df['assay_id']==assay_id]\n",
    "    df_train = df_current.loc[df['Clustering']=='TRN']\n",
    "    df_tst = df_current.loc[df['Clustering']=='TST']\n",
    "    column=0\n",
    "    pvg_column = 0\n",
    "    # if df_train.shape[0] < 100:\n",
    "    #     continue\n",
    "    # if assay_id != np.int64(flag_first_assay):\n",
    "    #     continue\n",
    "    start = time.time()\n",
    "\n",
    "    subset_size = int(decay_tracker.calculate(df_train.shape[0])*df_train.shape[0])\n",
    "    list_subset_sizes.append(subset_size)\n",
    "    list_total_sizes.append(df_train.shape[0])\n",
    "    if assay_id == np.int64(flag_first_assay):\n",
    "        print(\"\\nThe current assay id is {} and initialisation size is {}\\n\".format(assay_id, subset_size))\n",
    "    pearson_trn[row][column] = assay_id\n",
    "    pearson_tst[row][column] = assay_id\n",
    "    column+=1\n",
    "\n",
    "    X = torch.tensor(df_train.iloc[:,10:]).to(device)[:subset_size]\n",
    "    y = torch.tensor(df_train.iloc[:,3]).to(device)[:subset_size]\n",
    "\n",
    "    start_2 = time.time()\n",
    "\n",
    "    # X = torch.tensor(df_train.iloc[:,10:]).to(device)[:subset_size]\n",
    "    # y = torch.tensor(df_train.iloc[:,3]).to(device)[:subset_size]\n",
    "    \n",
    "    if use_decomposition == True:\n",
    "        transformer = TruncatedSVD(n_components=10, random_state=42).fit(X)\n",
    "        X = transformer.transform(X)\n",
    "        with open('../models/{0}_{1}/transformer_{2}.pickle'.format(model,fingerprint,flag_first_assay),'wb') as f:\n",
    "                pickle.dump(transformer,f)\n",
    "\n",
    "    print(\"Subset selected in {}\".format(time.time() - start_2))\n",
    "    # # train_idx = np.random.choice(range(X.shape[0]), size=int(X.shape[0]*0.1), replace=False)\n",
    "    # train_idx = X.multinomial(num_samples=int(X.shape[0]*0.01), replacement=False)\n",
    "    # x_initial = X[train_idx]\n",
    "    # y_initial = y[train_idx]\n",
    "    # print(\"Selecte initial training subset {}\".format(time.time() - start_2))\n",
    "    # # x_initial = X[-(int(df_train.shape[0]*0.1)):-1]\n",
    "    # # y_initial = y[-(int(df_train.shape[0]*0.1)):-1]\n",
    "\n",
    "    # X = np.delete(X,train_idx, axis=0)\n",
    "    # y = np.delete(y,train_idx)\n",
    "\n",
    "    # X = np.array(pd.DataFrame(X).reset_index(drop=True))\n",
    "    # y = np.array(pd.DataFrame(y).reset_index(drop=True))\n",
    "\n",
    "    pearson_trn[row][column] = subset_size\n",
    "    pearson_tst[row][column] = subset_size\n",
    "    column+=1\n",
    "\n",
    "    pearson_trn[row][column] = df_train.shape[0]\n",
    "    pearson_tst[row][column] = df_tst.shape[0]\n",
    "    column+=1\n",
    "\n",
    "    # if flag_first_assay==True:\n",
    "    #     [[0 for i in range(len(acquisition_list))] for j in range(num_iterations)]\n",
    "    \n",
    "    if use_unified_file==True:\n",
    "        for gpr_model in clf_list:\n",
    "            if assay_id==np.int64(flag_first_assay):\n",
    "                print(\"Data is for model {} with acc_func {}\".format(gpr_model[\"model_name\"], gpr_model[\"acquisition_function_name\"]))\n",
    "            clf = gpr_model[\"model\"]\n",
    "            print(\"Before model creation : {}\".format(time.time() - start_2))\n",
    "            learner = BayesianOptimizer(\n",
    "                estimator=clf,\n",
    "                query_strategy=gpr_model[\"acquisition_function\"],\n",
    "                X_training=x_initial, y_training=y_initial\n",
    "            )\n",
    "            print(\"After model creation and training {}\".format(time.time() - start_2))\n",
    "            pvg_row=0\n",
    "            for n_query in range(num_iterations):\n",
    "                if assay_id==np.int64(flag_first_assay):\n",
    "                    # first_assay = assay_id\n",
    "                    if use_decomposition == True:\n",
    "                        with open('../models/{0}_{1}/transformer_{2}.pickle'.format(model,fingerprint,flag_first_assay),'rb') as f:\n",
    "                            transformer = pickle.load(f)\n",
    "                        predictions_first_assay = learner.predict(transformer.transform(np.array(df_train.iloc[:,10:])))\n",
    "                    else:\n",
    "                        predictions_first_assay = learner.predict(np.array(df_train.iloc[:,10:]))\n",
    "                    pearson_values_graph[pvg_row][pvg_column] = round(np.corrcoef(np.array(df_train.iloc[:,3]), predictions_first_assay)[0,1]**2,5)\n",
    "                    pvg_row+=1\n",
    "                try:\n",
    "                    query_idx,query_inst = learner.query(X, n_instances=20)\n",
    "                except AssertionError:\n",
    "                    print(\"Encountered a case where the number of intances is lower than utility\")\n",
    "                    # continue\n",
    "                # print(\"Iteration num = {} || Query index = {} || Y val = {}\".format(n_query,query_idx, y[query_idx]))\n",
    "                print(\"Time taken to query {}\".format(time.time() - start_2))\n",
    "                learner.teach(X=query_inst,y=y[query_idx])\n",
    "                # print(query_idx)\n",
    "                # X = np.delete(X,query_idx, axis=0)\n",
    "                # y = np.delete(y,query_idx.astype(int))\n",
    "            print('Training Process for acc func {} has been completed in '.format(gpr_model[\"acquisition_function_name\"],time.time()-start))    \n",
    "            # specific_model_count = 1\n",
    "            \n",
    "            with open('../models/{0}_{1}/{2}_{3}_{4}.pickle'.format(model,fingerprint,gpr_model[\"model_name\"],gpr_model[\"acquisition_function_name\"],flag_first_assay),'wb') as f:\n",
    "                pickle.dump(learner,f)\n",
    "            \n",
    "            # with open('../models/{0}_{1}/{2}_{3}_{4}.pickle'.format(model,fingerprint,gpr_model[\"model_name\"],gpr_model[\"acquisition_function_name\"],assay_id),'wb') as f:\n",
    "            #      learner = pickle.load(f)\n",
    "            if use_decomposition == True:\n",
    "                with open('../models/{0}_{1}/transformer_{2}.pickle'.format(model,fingerprint,flag_first_assay),'rb') as f:\n",
    "                    transformer = pickle.load(f)    \n",
    "                predictions = learner.predict(transformer.transform(np.array(df_train.iloc[:,10:])))\n",
    "            else:\n",
    "                predictions = learner.predict(np.array(df_train.iloc[:,10:]))\n",
    "            result_trn = round(np.corrcoef(np.array(df_train.iloc[:,3]), predictions)[0,1]**2,5)\n",
    "\n",
    "            if use_decomposition == True:\n",
    "                with open('../models/{0}_{1}/transformer_{2}.pickle'.format(model,fingerprint,flag_first_assay),'rb') as f:\n",
    "                    transformer = pickle.load(f)     \n",
    "                predictions = learner.predict(transformer.transform(np.array(df_tst.iloc[:,10:])))\n",
    "            else:\n",
    "                predictions = learner.predict(np.array(df_tst.iloc[:,10:]))\n",
    "            result_tst = round(np.corrcoef(np.array(df_tst.iloc[:,3]), predictions)[0,1]**2,5)\n",
    "\n",
    "            pearson_trn[row][column] = result_trn\n",
    "            pearson_tst[row][column] = result_tst\n",
    "            \n",
    "            column+=1\n",
    "            pvg_column+=1\n",
    "    else:\n",
    "        print(\"Feature is in the works.\")   \n",
    "    row+=1\n",
    "    count+=1\n",
    "    if count >= 3:\n",
    "            break\n",
    "print('Reached selected assay at time = {}'.format(time.time() - start))\n",
    "# except NameError:\n",
    "#     print('Key Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4698892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached selected assay at time = 785.049289226532\n"
     ]
    }
   ],
   "source": [
    "print('Reached selected assay at time = {}'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c8509c",
   "metadata": {},
   "source": [
    "# row+=1\n",
    "for i in range(3,column):\n",
    "    # value_trn = np.mean(np.array(pearson_trn)[:,i])\n",
    "    # value_tst = np.mean(np.array(pearson_trn)[:,i])\n",
    "    \n",
    "    column_trn = np.array(pearson_trn)[:,i]\n",
    "    column_trn = column_trn[:row]\n",
    "\n",
    "    column_tst = np.array(pearson_tst)[:,i]\n",
    "    column_tst = column_tst[:row]\n",
    "\n",
    "    pearson_trn[row][i] = np.mean(column_trn)\n",
    "    pearson_tst[row][i] = np.mean(column_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abb7dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3e-05, 3e-05, 3e-05],\n",
       " [6e-05, 5e-05, 4e-05],\n",
       " [4e-05, 6e-05, 6e-05],\n",
       " [8e-05, 7e-05, 0.0001],\n",
       " [0.0001, 9e-05, 9e-05],\n",
       " [9e-05, 0.00012, 0.00014],\n",
       " [0.00012, 0.00017, 0.00015],\n",
       " [0.00011, 0.00015, 0.00015],\n",
       " [0.00011, 0.00014, 0.00015],\n",
       " [0.00011, 0.00019, 0.00014],\n",
       " [0.00011, 0.00014, 0.00012],\n",
       " [0.00012, 0.00016, 0.00012],\n",
       " [0.00011, 0.00016, 0.00015],\n",
       " [0.00011, 0.00017, 0.00018],\n",
       " [0.00012, 0.0002, 0.00024],\n",
       " [0.00012, 0.00018, 0.00023],\n",
       " [0.00011, 0.0002, 0.00029],\n",
       " [0.00011, 0.0003, 0.00034],\n",
       " [0.00011, 0.00034, 0.00033],\n",
       " [0.00011, 0.00037, 0.00038],\n",
       " [0.0001, 0.00035, 0.00037],\n",
       " [0.00011, 0.00037, 0.00035],\n",
       " [0.00011, 0.00042, 0.00035],\n",
       " [0.00011, 0.00042, 0.00039],\n",
       " [0.00011, 0.00045, 0.0004]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearson_values_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab76e3c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12348/3909144984.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpearson_trn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclf_list_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../data/data_results/{0}_{1}/pearsons_training_set_{2}.csv'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfingerprint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_iterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpearson_tst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclf_list_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../data/data_results/{0}_{1}/pearsons_test_set_{2}.csv'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfingerprint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_iterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpearson_values_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpearson_values_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams_config\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"acquisition\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpearson_values_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../data/data_results/{0}_{1}/squared_pearson_{2}.csv'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfingerprint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mflag_first_assay\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(pearson_trn, columns=clf_list_names).to_csv('../data/data_results/{0}_{1}/pearsons_training_set_{2}.csv'.format(model,fingerprint,num_iterations),index=False)\n",
    "pd.DataFrame(pearson_tst, columns=clf_list_names).to_csv('../data/data_results/{0}_{1}/pearsons_test_set_{2}.csv'.format(model,fingerprint,num_iterations),index=False)\n",
    "\n",
    "pearson_values_graph = pd.DataFrame(pearson_values_graph, columns=params_config[\"acquisition\"])\n",
    "pearson_values_graph.to_csv('../data/data_results/{0}_{1}/squared_pearson_{2}.csv'.format(model,fingerprint,flag_first_assay),index=False)\n",
    "\n",
    "colours = ['-r','--b',':g','^y','+p']\n",
    "colour_count = 0\n",
    "font_custom = {\n",
    "    \"family\" : \"sans-serif\",\n",
    "    \"color\" : \"darkblue\",\n",
    "    \"size\" : \"10\"\n",
    "    }\n",
    "\n",
    "plt.title(\"Training results for assay {}\".format(flag_first_assay), fontdict=font_custom, loc='center')\n",
    "plt.xlabel(\"Iteration number\", fontdict=font_custom)\n",
    "plt.ylabel(\"Pearson's coefficient values\", fontdict=font_custom)\n",
    "\n",
    "\n",
    "for (column_name,column_contents) in pearson_values_graph.iteritems():\n",
    "    plt.plot([x for x in range(len(column_contents))],column_contents, colours[colour_count], label='{}'.format(column_name))\n",
    "    colour_count +=1\n",
    "plt.grid(color = 'lightgreen', linestyle = '--', linewidth =0.25)\n",
    "plt.legend()\n",
    "plt.savefig('../data/data_results/{0}_{1}/plots/training_cycles_{2}.jpg'.format(model,fingerprint,flag_first_assay),\n",
    "                format='jpg',\n",
    "               )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0929b3e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
