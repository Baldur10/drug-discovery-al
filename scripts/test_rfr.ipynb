{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50599b14",
   "metadata": {},
   "source": [
    "# Test Script - Random Forest Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc93dc60",
   "metadata": {},
   "source": [
    "## Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c6d8c75-048b-465c-809d-b0343b8e37a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "\n",
    "# Importing Scikit-Learn Models\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearnex.ensemble import RandomForestRegressor\n",
    "\n",
    "# Importing Bayesian Optimizer and Acquisition Functions\n",
    "from modAL.models import BayesianOptimizer, CommitteeRegressor\n",
    "from modAL.acquisition import max_EI, max_PI, max_UCB\n",
    "\n",
    "# Importing Custom Acquisiton Functions and Decay Functions\n",
    "from utils import StepWiseDecay as SWD\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef636e3c",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cd5e57",
   "metadata": {},
   "source": [
    "Parameterised Cell Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99eb81b0-f36c-44af-9915-5e399d1d4e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "fingerprint = 'morgan'\n",
    "model = 'RFR'\n",
    "file_name = \"complete_file_morgan.feather\"\n",
    "config_file_name = 'RFR.json'\n",
    "use_subset = False\n",
    "use_unified_file = True\n",
    "assay_limit = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddef2ef",
   "metadata": {},
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "406f063f-1870-42b3-9386-4a9306d0d6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "file_path = '/data_temp/default_{}/'.format(fingerprint)\n",
    "\n",
    "try:\n",
    "    if use_unified_file == True:\n",
    "        try:\n",
    "            df = pd.read_feather(\"../data\" + file_path + file_name)\n",
    "        except:\n",
    "            df = pd.read_parquet(\"../data\" + file_path + file_name)\n",
    "        df_nan = pd.read_parquet(\"../data\" + file_path + \"assay_id/assay_id_null_file.parquet\")\n",
    "        df_assays = pd.read_parquet(\"../data\" + file_path + \"assay_id/assay_id_file.parquet\")\n",
    "\n",
    "    elif use_unified_file == False:\n",
    "        df_fingerprint = pd.read_parquet(\"../\" + file_path + \"/fingerprint/{}_fingerprint_file.parquet\".format(fingerprint))\n",
    "        df = pd.read_parquet(\"../\" + file_path + \"/preprocessed/preprocessed_file.parquet\")\n",
    "        df_nan = pd.read_parquet(\"../\" + file_path + \"/assay_id/assay_id_null_file.parquet\")\n",
    "        df_assays = pd.read_parquet(\"../\" + file_path + \"/assay_id/assay_id_file.parquet\")\n",
    "    else:\n",
    "        print(\"Incorrect value for 'use_unified_file' parameter passed. Please recheck.\")\n",
    "        pass\n",
    "except FileNotFoundError as e:\n",
    "    print(\"Data File not found: {}\".format(e))\n",
    "except OSError as e:    \n",
    "    print(\"Possible OS Error: {}\".format(e))\n",
    "    print('Kill all active kernels and restart the the Jupyter Kernel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f7ef3d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Rahil\\\\Documents\\\\Github\\\\drug-discovery-al\\\\scripts'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e16b6e5",
   "metadata": {},
   "source": [
    "Identifying noisy assays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aef88d7f-4cce-492c-aa89-d8e39aa92473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assay_id</th>\n",
       "      <th>squared_pearson_trn</th>\n",
       "      <th>squared_pearson_tst</th>\n",
       "      <th>assay_length_trn</th>\n",
       "      <th>assay_length_tst</th>\n",
       "      <th>assay_length_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>303216</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45</td>\n",
       "      <td>15</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>303260</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45</td>\n",
       "      <td>15</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>737235</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45</td>\n",
       "      <td>15</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   assay_id  squared_pearson_trn  squared_pearson_tst  assay_length_trn  \\\n",
       "1    303216                  NaN                  NaN                45   \n",
       "2    303260                  NaN                  NaN                45   \n",
       "4    737235                  NaN                  NaN                45   \n",
       "\n",
       "   assay_length_tst  assay_length_total  \n",
       "1                15                  60  \n",
       "2                15                  60  \n",
       "4                15                  60  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nan.loc[df_nan['squared_pearson_trn'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e22c5a",
   "metadata": {},
   "source": [
    "Removing Noisy Assays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152e698e-a306-468c-bdf2-49906f197c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.drop(nan_assays)\n",
    "for i in df_nan.loc[df_nan['squared_pearson_trn'].isnull()]['assay_id']:\n",
    "    df = df.drop(labels = df.loc[df['assay_id']==i].index)\n",
    "df.loc[df['assay_id']==303216].head()\n",
    "print('x-----x-----x-----x')\n",
    "df.loc[df['assay_id']==303260].head()\n",
    "print('x-----x-----x-----x')\n",
    "df.loc[df['assay_id']==737235].head()\n",
    "print('x-----x-----x-----x')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9bc157",
   "metadata": {},
   "source": [
    "Loading Config Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4884ce64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading JSON config file\n",
    "try:\n",
    "    with open('../config/' + config_file_name) as f:\n",
    "        params_config = json.load(f)\n",
    "        print('JSON config file for {} successfully loaded'.format(model))\n",
    "except FileNotFoundError:\n",
    "    print('Config file for model {} is missing.Resorting to default params'.format(model))\n",
    "    with open('../config/{}_default.json'.format(model)) as f:\n",
    "        params_config = json.load(f)\n",
    "try:\n",
    "    with open('../config/decay_values.json') as f:\n",
    "        decay_list = json.load(f)\n",
    "        decay_list = decay_list[\"decay values\"]\n",
    "except:\n",
    "    decay_list = [1.0,0.75,0.5,0.25,0.125,0.1,0.05]\n",
    "    print('Config file for decay values is missing. Resorting to default values: {}'.format(decay_list))\n",
    "            \n",
    "if os.path.isdir('../models/{0}_{1}/'.format(model,fingerprint)) == False:\n",
    "    os.mkdir('../models/{0}_{1}/'.format(model,fingerprint))\n",
    "\n",
    "if os.path.isdir('../data/data_results/{0}_{1}/'.format(model,fingerprint)) == False:\n",
    "    os.mkdir('../data/data_results/{0}_{1}/'.format(model,fingerprint))\n",
    "\n",
    "if os.path.isdir('../data/data_results/{0}_{1}/plots'.format(model,fingerprint)) == False:\n",
    "    os.mkdir('../data/data_results/{0}_{1}/plots'.format(model,fingerprint))\n",
    "\n",
    "# Creating List of Classifiers\n",
    "clfs = []\n",
    "acquisition_list = []\n",
    "clf_list = []\n",
    "count = 0\n",
    "clf_list_names = []\n",
    "\n",
    "for ensemble_kernel in params_config[\"model\"]:\n",
    "    if ensemble_kernel == \"RandomForestRegressor()\":\n",
    "        clf_type = RandomForestRegressor(n_estimators=params_config[\"params\"][\"n_estimators\"],\n",
    "                                            criterion=params_config[\"params\"][\"criterion\"],\n",
    "                                            min_samples_leaf=params_config[\"params\"][\"min_samples_leaf\"],\n",
    "                                            n_jobs=-1)\n",
    "    else:\n",
    "        clf_type = RandomForestRegressor(n_jobs=-1)\n",
    "    clf = {\n",
    "        \"type\" : clf_type,\n",
    "        \"name\" : ensemble_kernel\n",
    "    }\n",
    "    clfs.append(clf)\n",
    "\n",
    "for function in params_config[\"acquisition\"]:\n",
    "    if function==\"max_EI\":\n",
    "        acquisition_type = max_EI\n",
    "    elif function==\"max_PI\":\n",
    "        acquisition_type = max_PI\n",
    "    elif function==\"max_UCB\":\n",
    "        acquisition_type = max_UCB\n",
    "    elif function==\"random\":\n",
    "        acquisition_type = utils.random_sampling\n",
    "    elif function==\"equivalent\":\n",
    "        acquisition_type = utils.equivalent_sampling\n",
    "    elif function==\"margin_entropy\":\n",
    "        acquisition_type = utils.margin_entropy_sampling\n",
    "    elif function==\"uncertainty_margin\":\n",
    "        acquisition_type = utils.uncertainty_margin_sampling\n",
    "    elif function==\"product_sampling\":\n",
    "        acquisition_type = utils.product_sampling\n",
    "    else:\n",
    "        acquisition_type = max_EI\n",
    "    acquisition = {\n",
    "        \"type\" : acquisition_type,\n",
    "        \"name\": function\n",
    "    }\n",
    "    acquisition_list.append(acquisition)\n",
    "\n",
    "for model_selected in clfs:\n",
    "    for ac_func in acquisition_list:\n",
    "        clf = {\n",
    "            \"model\" :model_selected[\"type\"],\n",
    "            \"model_name\" : model_selected[\"name\"],\n",
    "            \"acquisition_function\" :ac_func[\"type\"],\n",
    "            \"acquisition_function_name\" : ac_func[\"name\"]\n",
    "        }\n",
    "        clf_list.append(clf)\n",
    "        clf_list_names.append(\"model_{}_{}\".format(clf[\"model_name\"], clf[\"acquisition_function_name\"]))\n",
    "        count+=1\n",
    "\n",
    "clf_list_names = ['assay_id','subset_size','total_length'] + clf_list_names\n",
    "\n",
    "num_iterations=params_config[\"iterations\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7af0ae4",
   "metadata": {},
   "source": [
    "Creating the dynamic Result Data Matrix to store the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ce108e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_trn = [[0 for i in range(len(clf_list)+3)] for j in range(len(df[\"assay_id\"].unique()+1))]\n",
    "pearson_tst = [[0 for i in range(len(clf_list)+3)] for j in range(len(df[\"assay_id\"].unique()+1))]\n",
    "\n",
    "pearson_values_graph = [[0 for i in range(len(acquisition_list))] for j in range(num_iterations)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c20082e",
   "metadata": {},
   "source": [
    "Suppresing warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730b3a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed04a770",
   "metadata": {},
   "source": [
    "Confirming the number of committee's to be created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b10eb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_config[\"num_committee\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1f47fc",
   "metadata": {},
   "source": [
    "## Training Cyle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80d6e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_subset_sizes = []\n",
    "list_total_sizes = []\n",
    "row = 0\n",
    "column = 0\n",
    "pvg_column = 0\n",
    "pvg_row = 0\n",
    "\n",
    "# Assay for which graphs have to be generated\n",
    "# flag_first_assay = 688239\n",
    "# flag_first_assay = 517\n",
    "flag_first_assay = 70695\n",
    "\n",
    "# Intialising the Decay Function\n",
    "\n",
    "try:\n",
    "    decay_tracker = SWD(decay_list)\n",
    "    count = 0\n",
    "\n",
    "    for assay_id in df['assay_id'].unique():\n",
    "\n",
    "        # Isolating the training and testing samples for the specfic assay\n",
    "        df_current = df.loc[df['assay_id']==assay_id]\n",
    "        df_train = df_current.loc[df['Clustering']=='TRN']\n",
    "        df_tst = df_current.loc[df['Clustering']=='TST']\n",
    "        column=0\n",
    "        pvg_column = 0\n",
    "        \n",
    "        # Uncomment this snippet to generate model only for a single assay as specified by 'flag_first_assay'\n",
    "        if assay_id != np.int64(flag_first_assay):\n",
    "            continue\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        # Initialising the length of the required subset as dictated by the Decay Function\n",
    "        subset_size = int(decay_tracker.calculate(df_train.shape[0])*df_train.shape[0])\n",
    "        list_subset_sizes.append(subset_size)\n",
    "        list_total_sizes.append(df_train.shape[0])\n",
    "\n",
    "        pearson_trn[row][column] = assay_id\n",
    "        pearson_tst[row][column] = assay_id\n",
    "        column+=1\n",
    "\n",
    "        # Whether to use subset of the entire sample space as the query space\n",
    "        if use_subset == True:\n",
    "            X = np.array(df_train.iloc[:,10:])[:subset_size]\n",
    "            y = np.array(df_train.iloc[:,3])[:subset_size]\n",
    "        else:\n",
    "            X = np.array(df_train.iloc[:,10:])\n",
    "            y = np.array(df_train.iloc[:,3])\n",
    "\n",
    "        pearson_trn[row][column] = subset_size\n",
    "        pearson_tst[row][column] = subset_size\n",
    "        column+=1\n",
    "\n",
    "        pearson_trn[row][column] = df_train.shape[0]\n",
    "        pearson_tst[row][column] = df_tst.shape[0]\n",
    "        column+=1\n",
    "        \n",
    "        if use_unified_file==True:\n",
    "            for gpr_model in clf_list:\n",
    "\n",
    "                # Training cycle for each model-acquistion function pairs\n",
    "                if assay_id==np.int64(flag_first_assay):\n",
    "                    print(\"Data is for model {} with acc_func {}\".format(gpr_model[\"model_name\"], gpr_model[\"acquisition_function_name\"]))\n",
    "                learner_list = []\n",
    "                X_train = X\n",
    "                y_train = y\n",
    "\n",
    "                # Creating the list of BayesianOptimizer objects with initial training values\n",
    "                for member_idx  in range(params_config[\"num_committee\"]):\n",
    "                    \n",
    "                    train_idx = np.random.choice(range(X_train.shape[0]), size=int(X.shape[0]*0.1), replace=False)\n",
    "                    \n",
    "\n",
    "                    x_initial = X_train[train_idx]\n",
    "                    y_initial = y_train[train_idx]\n",
    "\n",
    "                    X_train = np.delete(X_train,train_idx, axis=0)\n",
    "                    y_train = np.delete(y_train,train_idx)\n",
    "\n",
    "\n",
    "                    clf = gpr_model[\"model\"]\n",
    "\n",
    "                    # Creating the BayesianOptimizer object with the initial values\n",
    "                    learner = BayesianOptimizer(\n",
    "                        estimator=GridSearchCV(clf,params_config[\"param_grid\"],n_jobs=-1,cv=5 if 5 < int(x_initial.shape[0]) else int(x_initial.shape[0])),\n",
    "                        query_strategy=gpr_model[\"acquisition_function\"],\n",
    "                        X_training=x_initial, y_training=y_initial\n",
    "                    )\n",
    "                    learner_list.append(learner)\n",
    "                \n",
    "                # Creating the Committee Object from the list of BayesianOptimizer objects\n",
    "                committee = CommitteeRegressor(learner_list=learner_list)\n",
    "                print('Completed Generation of Committee object.')\n",
    "\n",
    "                pvg_row=0\n",
    "                for n_query in range(num_iterations):\n",
    "                    if assay_id==np.int64(flag_first_assay):\n",
    "                        first_assay = assay_id\n",
    "                        predictions_first_assay = committee.predict(np.array(df_train.iloc[:,10:]))\n",
    "                        pearson_values_graph[pvg_row][pvg_column] = round(np.corrcoef(np.array(df_train.iloc[:,3]), predictions_first_assay)[0,1]**2,5)\n",
    "                        pvg_row+=1\n",
    "                    \n",
    "                    # Querying samples from the the query space\n",
    "                    query_idx,query_inst = committee.query(X_train, n_instances=20)\n",
    "\n",
    "                    # Teaching the Committee Object\n",
    "                    committee.teach(X=query_inst,y=y_train[query_idx])\n",
    "                \n",
    "                # Saving the generated model\n",
    "                with open('../models/{0}_{1}/{2}_{3}_{4}.pickle'.format(model,fingerprint,gpr_model[\"model_name\"],gpr_model[\"acquisition_function_name\"],assay_id),'wb') as f:\n",
    "                    pickle.dump(committee,f)\n",
    "                \n",
    "                # Loading the pre-generated model\n",
    "                with open('../models/{0}_{1}/{2}_{3}_{4}.pickle'.format(model,fingerprint,gpr_model[\"model_name\"],gpr_model[\"acquisition_function_name\"],assay_id),'rb') as f:\n",
    "                     learner = pickle.load(f)\n",
    "                \n",
    "                # Predict model performance on the training samples\n",
    "                predictions = committee.predict(np.array(df_train.iloc[:,10:]))\n",
    "                result_trn = round(np.corrcoef(np.array(df_train.iloc[:,3]), predictions)[0,1]**2,5)\n",
    "\n",
    "                # Predict model performance on the testing samples\n",
    "                predictions = committee.predict(np.array(df_tst.iloc[:,10:]))\n",
    "                result_tst = round(np.corrcoef(np.array(df_tst.iloc[:,3]), predictions)[0,1]**2,5)\n",
    "\n",
    "                # Saving the model predictions in the Result Data Matrix\n",
    "                pearson_trn[row][column] = result_trn\n",
    "                pearson_tst[row][column] = result_tst\n",
    "                \n",
    "                column+=1\n",
    "                pvg_column+=1\n",
    "        else:\n",
    "            print(\"Feature is in the works.\")   \n",
    "        row+=1\n",
    "        count+=1\n",
    "        print(\"Assays {} parsed\".format(count))\n",
    "        if count >= assay_limit:\n",
    "             break\n",
    "\n",
    "except NameError:\n",
    "    print('Key Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43338922",
   "metadata": {},
   "source": [
    "Displaying the time taken for model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4698892",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Reached selected assay at time = {}'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20a7ce1",
   "metadata": {},
   "source": [
    "Results of the selected assay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abb7dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_values_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab76e3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(pearson_trn, columns=clf_list_names).to_csv('../data/data_results/{0}_{1}/pearsons_training_set_{2}.csv'.format(model,fingerprint,num_iterations),index=False)\n",
    "pd.DataFrame(pearson_tst, columns=clf_list_names).to_csv('../data/data_results/{0}_{1}/pearsons_test_set_{2}.csv'.format(model,fingerprint,num_iterations),index=False)\n",
    "\n",
    "pearson_values_graph = pd.DataFrame(pearson_values_graph, columns=params_config[\"acquisition\"])\n",
    "pearson_values_graph.to_csv('../data/data_results/{0}_{1}/squared_pearson_{2}.csv'.format(model,fingerprint,flag_first_assay),index=False)\n",
    "\n",
    "colours = ['-r','+b',':g','^y','--p']\n",
    "colour_count = 0\n",
    "font_custom = {\n",
    "    \"family\" : \"sans-serif\",\n",
    "    \"color\" : \"darkblue\",\n",
    "    \"size\" : \"10\"\n",
    "    }\n",
    "\n",
    "plt.title(\"Training results for assay {}\".format(flag_first_assay), fontdict=font_custom, loc='center')\n",
    "plt.xlabel(\"Iteration number\", fontdict=font_custom)\n",
    "plt.ylabel(\"Pearson's coefficient values\", fontdict=font_custom)\n",
    "\n",
    "\n",
    "for (column_name,column_contents) in pearson_values_graph.iteritems():\n",
    "    plt.plot([x for x in range(len(column_contents))],column_contents, colours[colour_count], label='{}'.format(column_name))\n",
    "    colour_count +=1\n",
    "plt.grid(color = 'lightgreen', linestyle = '--', linewidth =0.25)\n",
    "plt.legend()\n",
    "plt.savefig('../data/data_results/{0}_{1}/plots/training_cycles_{2}.jpg'.format(model,fingerprint,flag_first_assay),\n",
    "                format='jpg',\n",
    "               )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aadbd99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
